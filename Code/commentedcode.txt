# Run the models and print the results
#model = linear_model.LinearRegression()
# model_mse = 0
# model_r2 = 0
# i=0
# for train, test in kf.split(X_model, Y):
# 	model.fit(X_model[train], Y[train])
# 	y_pred = model.predict(X_model[test])
# 	model_mse += mean_squared_error(Y[test], y_pred)
# 	model_r2 += r2_score(Y[test], y_pred)
# 	i+=1

# print("DEBUG: LINEAR Average R2 value for the model was %s" % (model_r2/i))
# print("DEBUG: LINEAR Average MSE value for the model was %s" % (model_mse/i))


# draft_capital_only = PoissonRegressor(alpha=1/(.75*X_model.shape[0]), max_iter=500)


# draft_cap_mse = 0
# draft_cap_r2 = 0
# i=0
# for train, test in kf.split(X_draftcap, Y):
# 	draft_capital_only.fit(X_draftcap[train], Y[train].ravel())
# 	y_pred = draft_capital_only.predict(X_draftcap[test])
# 	draft_cap_mse += mean_squared_error(Y[test], y_pred)
# 	draft_cap_r2 += mean_poisson_deviance(Y[test], y_pred)
# 	i+=1

# print("DEBUG: POISSON Average D2 value for just draft capital was %s" % (draft_cap_r2/i))
# print("DEBUG: POISSON Average MSE value for just draft capital %s" % (draft_cap_mse/i))


filtered_cols = wr_data[[('Unnamed: 0_level_0', 'Name'), ('Unnamed: 1_level_0', 'School'), ("Unnamed: 4_level_0",'DP'), ("Breakout Ages", ">20%"), ("Breakout Ages", ">30%"), 
("RecYds/TmPatt", "BEST"), ("Dominator", "BEST"), ("Context Scores", "PPG Above conference expectation (Last Year)"), ("Context Scores", "TeamMate Score"), 
("Combine", "WaSS"), ("Combine", "BMI")]]/

# let's graph it

# model_x_train, model_x_test, model_draft_train, model_draft_test, model_y_train, model_y_test = train_test_split(X_model, X_draftcap, Y, test_size=.1, shuffle=True)

# model.fit(model_x_train, model_y_train.ravel())
# draft_capital_only.fit(model_draft_train, model_y_train)

# model_pred = model.predict(model_x_test)
# draft_cap_pred = draft_capital_only.predict(model_draft_test)

# plt.plot(range(len(model_pred)), model_pred, "g--", range(len(model_pred)), model_y_test, "r^", range(len(model_pred)), draft_cap_pred, "b--")
# plt.xlabel("index of observation")
# plt.ylabel("score - model in green, draft capital in blue, actual in red")
# plt.title("Predicting scores of Wide Receiver Prospects")
# plt.grid(True)
# plt.show()

finish_cols = wr_data[[('Unnamed: 0_level_0', 'Name'), ("Unnamed: 4_level_0",'DP'), ("Unnamed: 6_level_0",'Draft Year'), ("NFL Career Marks since 2000", "# of top 5  finishes"), ("NFL Career Marks since 2000", "# of top  12 finishes"), 
("NFL Career Marks since 2000", "# of top  24 finishes"), ("NFL Career Marks since 2000", "# of top  36 finishes")]]
finish_cols.fillna("0", inplace=True)

# we are going to create a dataframe with the name and score

name_and_score = []

for index,row in finish_cols.iterrows():
	real_top_36 = int(row["NFL Career Marks since 2000"]["# of top  36 finishes"]) - int(row["NFL Career Marks since 2000"]["# of top  24 finishes"])
	real_top_24 = int(row["NFL Career Marks since 2000"]["# of top  24 finishes"]) - int(row["NFL Career Marks since 2000"]["# of top  12 finishes"])
	real_top_12 = int(row["NFL Career Marks since 2000"]["# of top  12 finishes"]) - int(row["NFL Career Marks since 2000"]["# of top 5  finishes"])
	real_top_5 = int(row["NFL Career Marks since 2000"]["# of top 5  finishes"])
	score = real_top_36 + 2*real_top_24 + 4*real_top_12 + 8*real_top_5
	print("DEBUG: score for %s is %s" % (row['Unnamed: 0_level_0']['Name'], score))
	total_years = helpers.get_total_years(row, players_final_year)
	score = score/total_years
	name_and_score.append([row['Unnamed: 0_level_0']['Name'], score])

name_and_score = pd.DataFrame(name_and_score, columns=["Name", "Score"])

# sort by alphabetical names

print("DEBUG: ###################################")
print(name_and_score)
print("DEBUG: ###################################")

# import the data for players final year to get the end date for player's careers

players_final_year = pd.read_excel("/Users/ronakmodi/FF_ProspectModel/Data/player_final_year.xlsx", sheet_name = "main")
print("DEBUG: ###################################")
print(list(players_final_year.columns))
print("DEBUG: ###################################")


model = PoissonRegressor(alpha=1/X_model.shape[0], max_iter=1000)

model_mse = 0
model_mae = 0
model_r2 = 0
i=0
for train, test in kf.split(X_model, Y):
	model.fit(X_model[train], Y[train].ravel())
	y_pred = model.predict(X_model[test])
	model_mse += mean_squared_error(Y[test], y_pred)
	model_mae += mean_absolute_error(Y[test], y_pred)
	model_r2 += r2_score(Y[test], y_pred)
	i+=1

print("DEBUG: POISSON Average R2 value for the model was %s" % (model_r2/i))
print("DEBUG: POISSON Average MAE value for the model was %s" % (model_mae/i))
print("DEBUG: POISSON Average MSE value for the model was %s\n" % (model_mse/i))



# take the log of draft capital

# filtered_columns.loc[:, ("Unnamed: 4_level_0", 'DP')] = np.log(filtered_columns["Unnamed: 4_level_0"]['DP'])
# draft_capital_only.loc[:, ("Unnamed: 4_level_0", 'DP')] = np.log(draft_capital_only["Unnamed: 4_level_0"]['DP'])


# Pre-process X_model so that some columns are one-hot encoded

# transformer = ColumnTransformer(
# 	[("encode_schools", OneHotEncoder(), [0])],
# 	remainder="passthrough"
# 	)

# X_model = transformer.fit_transform(X_model)

# model_x_train, model_x_test, model_y_train, model_y_test = train_test_split(X_model, Y, test_size=.1, shuffle=True)

# model.fit(model_x_train,model_y_train.ravel())
# r_2 = model.score(model_x_test,model_y_test.ravel())

# print("DEBUG: ENSEMBLE r^2 value was %s" % r_2)

# feature_weight = pd.DataFrame({"Feature": model_columns.columns.tolist(), "Importance": model.feature_importances_})
# print(feature_weight)

